# ============================================
# Environment Configuration
# ============================================
# SETUP INSTRUCTIONS:
# 1. Copy this file: cp .env.example .env
# 2. Update REQUIRED fields marked with ⚠️
# 3. Optional fields can be left as-is for development
# ============================================

# ============================================
# Database Configuration
# ============================================
# ⚠️ REQUIRED: Change password before first run
POSTGRES_USER=postgres
POSTGRES_PASSWORD=your_secure_password_here
POSTGRES_DB=lecture_notes
POSTGRES_HOST=localhost
POSTGRES_PORT=5432

# Note: DATABASE_URL is constructed automatically from the above values if not provided.
# If you provide it here, some components might use it directly.
# DATABASE_URL=postgresql+asyncpg://postgres:your_secure_password_here@localhost:5432/lecture_notes

# ============================================
# Redis Configuration
# ============================================
# Optional: Default values work for local development
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_URL=redis://localhost:6379

# ============================================
# Application Settings
# ============================================
APP_NAME=AI Lecture Note Summarizer
APP_VERSION=0.1.0

# ⚠️ REQUIRED: Set to False in production
DEBUG=True

# ⚠️ REQUIRED: Generate a secure random key for production
# Generate with: python -c "import secrets; print(secrets.token_urlsafe(32))"
SECRET_KEY=your_secret_key_here_change_in_production

# ============================================
# CORS Settings
# ============================================
# Comma-separated list of allowed origins
CORS_ORIGINS=http://localhost:3000,http://localhost:5173

# ============================================
# File Upload Configuration
# ============================================
MAX_UPLOAD_SIZE=52428800  # 50MB in bytes
ALLOWED_EXTENSIONS=pdf
UPLOAD_DIR=./uploads

# ============================================
# AI Models Configuration
# ============================================
# Embedding model for vector search
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
EMBEDDING_DIMENSION=384

# LLM for summarization (local, openai, anthropic, etc.)
LLM_MODEL=local

# SpaCy model for text chunking
# Download with: python -m spacy download en_core_web_sm
SPACY_MODEL=en_core_web_sm

# ============================================
# Vector Search Configuration
# ============================================
# HNSW (Hierarchical Navigable Small World) index settings
VECTOR_INDEX_TYPE=hnsw
HNSW_M=16
HNSW_EF_CONSTRUCTION=64

# ============================================
# Text Chunking Configuration
# ============================================
# These values are used by the PDFSegmenter service
CHUNK_SIZE_TOKENS=512
MAX_CHUNK_SIZE=1024
MIN_CHUNK_SIZE=100
CHUNK_OVERLAP=50
OVERLAP_PERCENTAGE=0.1  # 10% overlap

# ============================================
# Error Handling & Resilience
# ============================================
MAX_RETRY_ATTEMPTS=3
RETRY_BACKOFF_FACTOR=2.0
RETRY_MAX_DELAY=30
DATABASE_TIMEOUT=30
CIRCUIT_BREAKER_THRESHOLD=5
CIRCUIT_BREAKER_TIMEOUT=60

# ============================================
# External API Keys (Optional)
# ============================================
# OpenAI API (for GPT models)
# OPENAI_API_KEY=sk-your_openai_key_here

# Anthropic API (for Claude models)
# ANTHROPIC_API_KEY=sk-ant-your_anthropic_key_here

# ============================================
# Development vs Production
# ============================================
# For production deployment:
# 1. Set DEBUG=False
# 2. Generate new SECRET_KEY
# 3. Use strong POSTGRES_PASSWORD
# 4. Update CORS_ORIGINS to production domains
# 5. Consider using environment-specific .env files
